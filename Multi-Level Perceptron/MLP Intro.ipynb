{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "  16BCE1259\n",
    "  \n",
    "  Shushil Kumar Ravishankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           1           DRC01         5.92          Regular         0.019278   \n",
       "2           2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           3           FDX07        19.20          Regular         0.000000   \n",
       "4           4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998      Medium               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('clean_bmart.csv',sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 1 0]\n",
      "[[156 9.3 0 ... 0 1 3735.138]\n",
      " [659 17.5 0 ... 0 1 2097.27]\n",
      " [438 16.2 1 ... 0 1 1076.5986]\n",
      " ...\n",
      " [890 8.38 1 ... 0 1 549.285]\n",
      " [1348 10.6 0 ... 1 1 1193.1136]\n",
      " [50 14.8 0 ... 1 1 765.67]]\n",
      "['Item_Visibility' 'Outlet_Establishment_Year' 'Outlet_Location_Type']\n"
     ]
    }
   ],
   "source": [
    "X=data.loc[(data['Outlet_Location_Type']=='Tier 1')|(data['Outlet_Location_Type']=='Tier 2')]\n",
    "x=X.values[:,:]\n",
    "y=X.values[:,10]\n",
    "ley=LabelEncoder()\n",
    "ley.fit(y)\n",
    "y=ley.transform(y)\n",
    "for i in [1,3,5,7,9,11]:\n",
    "    en=LabelEncoder()\n",
    "    en.fit(X.values[:,i])\n",
    "    x[:,i]=en.transform(x[:,i])\n",
    "\n",
    "x=x[:,[1,2,3,4,5,6,7,8,9,11,12]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print(y)\n",
    "print(x)\n",
    "print(data.columns.values[[4,8,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (9) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "error=[]\n",
    "iteration=[]\n",
    "for i in range(1,1000):\n",
    "    iteration.append(i)\n",
    "    mlp=MLPClassifier(hidden_layer_sizes=(5),max_iter=i,random_state=0)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions=mlp.predict(X_test)\n",
    "    error.append(1-accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration,error,color='g')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error VS no of iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.index(min(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp=MLPClassifier(hidden_layer_sizes=(5),max_iter=error.index(min(error))+1,random_state=0)\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions=mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[597  97]\n",
      " [ 97 761]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "size=[]\n",
    "error=[]\n",
    "for i in range(0,10):\n",
    "    for j in range(0,10):\n",
    "        for k in range(0,10):\n",
    "            var=[]\n",
    "            if i!=0:\n",
    "                var.append(i)\n",
    "            if j!=0:\n",
    "                var.append(j)\n",
    "            if k!=0:\n",
    "                var.append(k)\n",
    "            if var!=[]:\n",
    "                size.append(tuple(var))\n",
    "for i in size:\n",
    "    mlp=MLPClassifier(hidden_layer_sizes=i,max_iter=54,random_state=0)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions=mlp.predict(X_test)\n",
    "    error.append(1-accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=[]\n",
    "for i in range(len(size)):\n",
    "    table.append([size[i],error[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size          Error\n",
      "---------  --------\n",
      "(1,)       0.447165\n",
      "(2,)       0.462629\n",
      "(3,)       0.447165\n",
      "(4,)       0.373067\n",
      "(5,)       0.125\n",
      "(6,)       0.439433\n",
      "(7,)       0.256443\n",
      "(8,)       0.559278\n",
      "(9,)       0.39884\n",
      "(1,)       0.447165\n",
      "(1, 1)     0.552835\n",
      "(1, 2)     0.447165\n",
      "(1, 3)     0.447165\n",
      "(1, 4)     0.447165\n",
      "(1, 5)     0.447165\n",
      "(1, 6)     0.409794\n",
      "(1, 7)     0.447165\n",
      "(1, 8)     0.58183\n",
      "(1, 9)     0.447165\n",
      "(2,)       0.462629\n",
      "(2, 1)     0.447165\n",
      "(2, 2)     0.536082\n",
      "(2, 3)     0.496134\n",
      "(2, 4)     0.539948\n",
      "(2, 5)     0.46134\n",
      "(2, 6)     0.440722\n",
      "(2, 7)     0.448454\n",
      "(2, 8)     0.446521\n",
      "(2, 9)     0.461985\n",
      "(3,)       0.447165\n",
      "(3, 1)     0.552835\n",
      "(3, 2)     0.552191\n",
      "(3, 3)     0.349227\n",
      "(3, 4)     0.438789\n",
      "(3, 5)     0.606314\n",
      "(3, 6)     0.411727\n",
      "(3, 7)     0.5\n",
      "(3, 8)     0.499356\n",
      "(3, 9)     0.42268\n",
      "(4,)       0.373067\n",
      "(4, 1)     0.552835\n",
      "(4, 2)     0.537371\n",
      "(4, 3)     0.447165\n",
      "(4, 4)     0.447165\n",
      "(4, 5)     0.376933\n",
      "(4, 6)     0.405928\n",
      "(4, 7)     0.366624\n",
      "(4, 8)     0.367268\n",
      "(4, 9)     0.429124\n",
      "(5,)       0.125\n",
      "(5, 1)     0.550902\n",
      "(5, 2)     0.447165\n",
      "(5, 3)     0.4375\n",
      "(5, 4)     0.447165\n",
      "(5, 5)     0.501289\n",
      "(5, 6)     0.262242\n",
      "(5, 7)     0.385309\n",
      "(5, 8)     0.375644\n",
      "(5, 9)     0.429124\n",
      "(6,)       0.439433\n",
      "(6, 1)     0.552835\n",
      "(6, 2)     0.447165\n",
      "(6, 3)     0.402706\n",
      "(6, 4)     0.527062\n",
      "(6, 5)     0.414948\n",
      "(6, 6)     0.378222\n",
      "(6, 7)     0.38982\n",
      "(6, 8)     0.471005\n",
      "(6, 9)     0.375644\n",
      "(7,)       0.256443\n",
      "(7, 1)     0.447165\n",
      "(7, 2)     0.447165\n",
      "(7, 3)     0.382088\n",
      "(7, 4)     0.422036\n",
      "(7, 5)     0.37951\n",
      "(7, 6)     0.32732\n",
      "(7, 7)     0.429768\n",
      "(7, 8)     0.466495\n",
      "(7, 9)     0.449098\n",
      "(8,)       0.559278\n",
      "(8, 1)     0.447165\n",
      "(8, 2)     0.447165\n",
      "(8, 3)     0.510954\n",
      "(8, 4)     0.399485\n",
      "(8, 5)     0.378222\n",
      "(8, 6)     0.43299\n",
      "(8, 7)     0.414948\n",
      "(8, 8)     0.499356\n",
      "(8, 9)     0.376289\n",
      "(9,)       0.39884\n",
      "(9, 1)     0.447165\n",
      "(9, 2)     0.522552\n",
      "(9, 3)     0.404639\n",
      "(9, 4)     0.503866\n",
      "(9, 5)     0.579897\n",
      "(9, 6)     0.400773\n",
      "(9, 7)     0.513531\n",
      "(9, 8)     0.516753\n",
      "(9, 9)     0.380799\n",
      "(1,)       0.447165\n",
      "(1, 1)     0.552835\n",
      "(1, 2)     0.447165\n",
      "(1, 3)     0.447165\n",
      "(1, 4)     0.447165\n",
      "(1, 5)     0.447165\n",
      "(1, 6)     0.409794\n",
      "(1, 7)     0.447165\n",
      "(1, 8)     0.58183\n",
      "(1, 9)     0.447165\n",
      "(1, 1)     0.552835\n",
      "(1, 1, 1)  0.447165\n",
      "(1, 1, 2)  0.447165\n",
      "(1, 1, 3)  0.447165\n",
      "(1, 1, 4)  0.447165\n",
      "(1, 1, 5)  0.447165\n",
      "(1, 1, 6)  0.447165\n",
      "(1, 1, 7)  0.391108\n",
      "(1, 1, 8)  0.494845\n",
      "(1, 1, 9)  0.447165\n",
      "(1, 2)     0.447165\n",
      "(1, 2, 1)  0.447165\n",
      "(1, 2, 2)  0.447165\n",
      "(1, 2, 3)  0.409149\n",
      "(1, 2, 4)  0.447165\n",
      "(1, 2, 5)  0.447165\n",
      "(1, 2, 6)  0.447165\n",
      "(1, 2, 7)  0.447165\n",
      "(1, 2, 8)  0.552835\n",
      "(1, 2, 9)  0.447165\n",
      "(1, 3)     0.447165\n",
      "(1, 3, 1)  0.552835\n",
      "(1, 3, 2)  0.447165\n",
      "(1, 3, 3)  0.552835\n",
      "(1, 3, 4)  0.466495\n",
      "(1, 3, 5)  0.447165\n",
      "(1, 3, 6)  0.552835\n",
      "(1, 3, 7)  0.502577\n",
      "(1, 3, 8)  0.447165\n",
      "(1, 3, 9)  0.552835\n",
      "(1, 4)     0.447165\n",
      "(1, 4, 1)  0.447165\n",
      "(1, 4, 2)  0.447165\n",
      "(1, 4, 3)  0.447165\n",
      "(1, 4, 4)  0.552835\n",
      "(1, 4, 5)  0.552835\n",
      "(1, 4, 6)  0.552835\n",
      "(1, 4, 7)  0.552835\n",
      "(1, 4, 8)  0.552835\n",
      "(1, 4, 9)  0.552835\n",
      "(1, 5)     0.447165\n",
      "(1, 5, 1)  0.43299\n",
      "(1, 5, 2)  0.447165\n",
      "(1, 5, 3)  0.447165\n",
      "(1, 5, 4)  0.552835\n",
      "(1, 5, 5)  0.447165\n",
      "(1, 5, 6)  0.552835\n",
      "(1, 5, 7)  0.447165\n",
      "(1, 5, 8)  0.552835\n",
      "(1, 5, 9)  0.548325\n",
      "(1, 6)     0.409794\n",
      "(1, 6, 1)  0.447165\n",
      "(1, 6, 2)  0.447165\n",
      "(1, 6, 3)  0.447165\n",
      "(1, 6, 4)  0.552835\n",
      "(1, 6, 5)  0.552835\n",
      "(1, 6, 6)  0.447165\n",
      "(1, 6, 7)  0.447165\n",
      "(1, 6, 8)  0.54317\n",
      "(1, 6, 9)  0.552835\n",
      "(1, 7)     0.447165\n",
      "(1, 7, 1)  0.552835\n",
      "(1, 7, 2)  0.552835\n",
      "(1, 7, 3)  0.552835\n",
      "(1, 7, 4)  0.447165\n",
      "(1, 7, 5)  0.447165\n",
      "(1, 7, 6)  0.427191\n",
      "(1, 7, 7)  0.552835\n",
      "(1, 7, 8)  0.552835\n",
      "(1, 7, 9)  0.552835\n",
      "(1, 8)     0.58183\n",
      "(1, 8, 1)  0.447165\n",
      "(1, 8, 2)  0.552835\n",
      "(1, 8, 3)  0.447165\n",
      "(1, 8, 4)  0.447165\n",
      "(1, 8, 5)  0.552835\n",
      "(1, 8, 6)  0.447165\n",
      "(1, 8, 7)  0.552835\n",
      "(1, 8, 8)  0.536727\n",
      "(1, 8, 9)  0.447165\n",
      "(1, 9)     0.447165\n",
      "(1, 9, 1)  0.552835\n",
      "(1, 9, 2)  0.447165\n",
      "(1, 9, 3)  0.552835\n",
      "(1, 9, 4)  0.447165\n",
      "(1, 9, 5)  0.552835\n",
      "(1, 9, 6)  0.552835\n",
      "(1, 9, 7)  0.447165\n",
      "(1, 9, 8)  0.447165\n",
      "(1, 9, 9)  0.438144\n",
      "(2,)       0.462629\n",
      "(2, 1)     0.447165\n",
      "(2, 2)     0.536082\n",
      "(2, 3)     0.496134\n",
      "(2, 4)     0.539948\n",
      "(2, 5)     0.46134\n",
      "(2, 6)     0.440722\n",
      "(2, 7)     0.448454\n",
      "(2, 8)     0.446521\n",
      "(2, 9)     0.461985\n",
      "(2, 1)     0.447165\n",
      "(2, 1, 1)  0.552835\n",
      "(2, 1, 2)  0.447165\n",
      "(2, 1, 3)  0.447165\n",
      "(2, 1, 4)  0.447165\n",
      "(2, 1, 5)  0.447165\n",
      "(2, 1, 6)  0.447165\n",
      "(2, 1, 7)  0.447165\n",
      "(2, 1, 8)  0.447165\n",
      "(2, 1, 9)  0.447165\n",
      "(2, 2)     0.536082\n",
      "(2, 2, 1)  0.535438\n",
      "(2, 2, 2)  0.447165\n",
      "(2, 2, 3)  0.436856\n",
      "(2, 2, 4)  0.492268\n",
      "(2, 2, 5)  0.457474\n",
      "(2, 2, 6)  0.501933\n",
      "(2, 2, 7)  0.469716\n",
      "(2, 2, 8)  0.460696\n",
      "(2, 2, 9)  0.447165\n",
      "(2, 3)     0.496134\n",
      "(2, 3, 1)  0.447165\n",
      "(2, 3, 2)  0.498067\n",
      "(2, 3, 3)  0.435567\n",
      "(2, 3, 4)  0.38982\n",
      "(2, 3, 5)  0.417526\n",
      "(2, 3, 6)  0.454897\n",
      "(2, 3, 7)  0.447165\n",
      "(2, 3, 8)  0.494201\n",
      "(2, 3, 9)  0.552835\n",
      "(2, 4)     0.539948\n",
      "(2, 4, 1)  0.447165\n",
      "(2, 4, 2)  0.465851\n",
      "(2, 4, 3)  0.499356\n",
      "(2, 4, 4)  0.503222\n",
      "(2, 4, 5)  0.461985\n",
      "(2, 4, 6)  0.447165\n",
      "(2, 4, 7)  0.458763\n",
      "(2, 4, 8)  0.447809\n",
      "(2, 4, 9)  0.517397\n",
      "(2, 5)     0.46134\n",
      "(2, 5, 1)  0.552835\n",
      "(2, 5, 2)  0.545747\n",
      "(2, 5, 3)  0.460696\n",
      "(2, 5, 4)  0.458763\n",
      "(2, 5, 5)  0.449098\n",
      "(2, 5, 6)  0.420103\n",
      "(2, 5, 7)  0.398196\n",
      "(2, 5, 8)  0.438789\n",
      "(2, 5, 9)  0.449098\n",
      "(2, 6)     0.440722\n",
      "(2, 6, 1)  0.447165\n",
      "(2, 6, 2)  0.447165\n",
      "(2, 6, 3)  0.397552\n",
      "(2, 6, 4)  0.447165\n",
      "(2, 6, 5)  0.552835\n",
      "(2, 6, 6)  0.434923\n",
      "(2, 6, 7)  0.457474\n",
      "(2, 6, 8)  0.443299\n",
      "(2, 6, 9)  0.498067\n",
      "(2, 7)     0.448454\n",
      "(2, 7, 1)  0.552835\n",
      "(2, 7, 2)  0.550258\n",
      "(2, 7, 3)  0.430412\n",
      "(2, 7, 4)  0.402062\n",
      "(2, 7, 5)  0.431701\n",
      "(2, 7, 6)  0.542526\n",
      "(2, 7, 7)  0.505799\n",
      "(2, 7, 8)  0.447165\n",
      "(2, 7, 9)  0.478737\n",
      "(2, 8)     0.446521\n",
      "(2, 8, 1)  0.404639\n",
      "(2, 8, 2)  0.447165\n",
      "(2, 8, 3)  0.425902\n",
      "(2, 8, 4)  0.414948\n",
      "(2, 8, 5)  0.423969\n",
      "(2, 8, 6)  0.44201\n",
      "(2, 8, 7)  0.429124\n",
      "(2, 8, 8)  0.434278\n",
      "(2, 8, 9)  0.441366\n",
      "(2, 9)     0.461985\n",
      "(2, 9, 1)  0.447165\n",
      "(2, 9, 2)  0.447165\n",
      "(2, 9, 3)  0.447165\n",
      "(2, 9, 4)  0.550258\n",
      "(2, 9, 5)  0.414304\n",
      "(2, 9, 6)  0.440722\n",
      "(2, 9, 7)  0.444588\n",
      "(2, 9, 8)  0.418814\n",
      "(2, 9, 9)  0.470361\n",
      "(3,)       0.447165\n",
      "(3, 1)     0.552835\n",
      "(3, 2)     0.552191\n",
      "(3, 3)     0.349227\n",
      "(3, 4)     0.438789\n",
      "(3, 5)     0.606314\n",
      "(3, 6)     0.411727\n",
      "(3, 7)     0.5\n",
      "(3, 8)     0.499356\n",
      "(3, 9)     0.42268\n",
      "(3, 1)     0.552835\n",
      "(3, 1, 1)  0.552835\n",
      "(3, 1, 2)  0.552835\n",
      "(3, 1, 3)  0.552835\n",
      "(3, 1, 4)  0.389175\n",
      "(3, 1, 5)  0.590206\n",
      "(3, 1, 6)  0.552835\n",
      "(3, 1, 7)  0.489691\n",
      "(3, 1, 8)  0.552835\n",
      "(3, 1, 9)  0.552835\n",
      "(3, 2)     0.552191\n",
      "(3, 2, 1)  0.552835\n",
      "(3, 2, 2)  0.529639\n",
      "(3, 2, 3)  0.447165\n",
      "(3, 2, 4)  0.418814\n",
      "(3, 2, 5)  0.53866\n",
      "(3, 2, 6)  0.479381\n",
      "(3, 2, 7)  0.454897\n",
      "(3, 2, 8)  0.458763\n",
      "(3, 2, 9)  0.497423\n",
      "(3, 3)     0.349227\n",
      "(3, 3, 1)  0.552835\n",
      "(3, 3, 2)  0.447165\n",
      "(3, 3, 3)  0.467784\n",
      "(3, 3, 4)  0.401418\n",
      "(3, 3, 5)  0.447165\n",
      "(3, 3, 6)  0.420103\n",
      "(3, 3, 7)  0.552835\n",
      "(3, 3, 8)  0.505799\n",
      "(3, 3, 9)  0.390464\n",
      "(3, 4)     0.438789\n",
      "(3, 4, 1)  0.447165\n",
      "(3, 4, 2)  0.552835\n",
      "(3, 4, 3)  0.422036\n",
      "(3, 4, 4)  0.552191\n",
      "(3, 4, 5)  0.552835\n",
      "(3, 4, 6)  0.494845\n",
      "(3, 4, 7)  0.447809\n",
      "(3, 4, 8)  0.384665\n",
      "(3, 4, 9)  0.440722\n",
      "(3, 5)     0.606314\n",
      "(3, 5, 1)  0.552835\n",
      "(3, 5, 2)  0.447165\n",
      "(3, 5, 3)  0.391108\n",
      "(3, 5, 4)  0.440077\n",
      "(3, 5, 5)  0.408505\n",
      "(3, 5, 6)  0.420103\n",
      "(3, 5, 7)  0.409149\n",
      "(3, 5, 8)  0.387887\n",
      "(3, 5, 9)  0.396907\n",
      "(3, 6)     0.411727\n",
      "(3, 6, 1)  0.447165\n",
      "(3, 6, 2)  0.447165\n",
      "(3, 6, 3)  0.509021\n",
      "(3, 6, 4)  0.546392\n",
      "(3, 6, 5)  0.362758\n",
      "(3, 6, 6)  0.415593\n",
      "(3, 6, 7)  0.447165\n",
      "(3, 6, 8)  0.447165\n",
      "(3, 6, 9)  0.397552\n",
      "(3, 7)     0.5\n",
      "(3, 7, 1)  0.447165\n",
      "(3, 7, 2)  0.552835\n",
      "(3, 7, 3)  0.385954\n",
      "(3, 7, 4)  0.387242\n",
      "(3, 7, 5)  0.429124\n",
      "(3, 7, 6)  0.447165\n",
      "(3, 7, 7)  0.39433\n",
      "(3, 7, 8)  0.353093\n",
      "(3, 7, 9)  0.447165\n",
      "(3, 8)     0.499356\n",
      "(3, 8, 1)  0.552835\n",
      "(3, 8, 2)  0.447165\n",
      "(3, 8, 3)  0.552835\n",
      "(3, 8, 4)  0.342784\n",
      "(3, 8, 5)  0.388531\n",
      "(3, 8, 6)  0.384665\n",
      "(3, 8, 7)  0.445876\n",
      "(3, 8, 8)  0.439433\n",
      "(3, 8, 9)  0.458119\n",
      "(3, 9)     0.42268\n",
      "(3, 9, 1)  0.434278\n",
      "(3, 9, 2)  0.50451\n",
      "(3, 9, 3)  0.447165\n",
      "(3, 9, 4)  0.367912\n",
      "(3, 9, 5)  0.369845\n",
      "(3, 9, 6)  0.403995\n",
      "(3, 9, 7)  0.375644\n",
      "(3, 9, 8)  0.405928\n",
      "(3, 9, 9)  0.410438\n",
      "(4,)       0.373067\n",
      "(4, 1)     0.552835\n",
      "(4, 2)     0.537371\n",
      "(4, 3)     0.447165\n",
      "(4, 4)     0.447165\n",
      "(4, 5)     0.376933\n",
      "(4, 6)     0.405928\n",
      "(4, 7)     0.366624\n",
      "(4, 8)     0.367268\n",
      "(4, 9)     0.429124\n",
      "(4, 1)     0.552835\n",
      "(4, 1, 1)  0.447165\n",
      "(4, 1, 2)  0.447165\n",
      "(4, 1, 3)  0.393041\n",
      "(4, 1, 4)  0.447165\n",
      "(4, 1, 5)  0.447165\n",
      "(4, 1, 6)  0.447165\n",
      "(4, 1, 7)  0.447165\n",
      "(4, 1, 8)  0.448454\n",
      "(4, 1, 9)  0.384665\n",
      "(4, 2)     0.537371\n",
      "(4, 2, 1)  0.447165\n",
      "(4, 2, 2)  0.375\n",
      "(4, 2, 3)  0.391108\n",
      "(4, 2, 4)  0.447165\n",
      "(4, 2, 5)  0.391753\n",
      "(4, 2, 6)  0.552835\n",
      "(4, 2, 7)  0.375\n",
      "(4, 2, 8)  0.367912\n",
      "(4, 2, 9)  0.408505\n",
      "(4, 3)     0.447165\n",
      "(4, 3, 1)  0.404639\n",
      "(4, 3, 2)  0.447165\n",
      "(4, 3, 3)  0.414304\n",
      "(4, 3, 4)  0.449742\n",
      "(4, 3, 5)  0.447165\n",
      "(4, 3, 6)  0.439433\n",
      "(4, 3, 7)  0.440722\n",
      "(4, 3, 8)  0.420103\n",
      "(4, 3, 9)  0.420747\n",
      "(4, 4)     0.447165\n",
      "(4, 4, 1)  0.447165\n",
      "(4, 4, 2)  0.365335\n",
      "(4, 4, 3)  0.452964\n",
      "(4, 4, 4)  0.383376\n",
      "(4, 4, 5)  0.451031\n",
      "(4, 4, 6)  0.356959\n",
      "(4, 4, 7)  0.356959\n",
      "(4, 4, 8)  0.432345\n",
      "(4, 4, 9)  0.427191\n",
      "(4, 5)     0.376933\n",
      "(4, 5, 1)  0.447165\n",
      "(4, 5, 2)  0.552835\n",
      "(4, 5, 3)  0.391753\n",
      "(4, 5, 4)  0.447165\n",
      "(4, 5, 5)  0.367912\n",
      "(4, 5, 6)  0.384665\n",
      "(4, 5, 7)  0.372423\n",
      "(4, 5, 8)  0.380155\n",
      "(4, 5, 9)  0.363402\n",
      "(4, 6)     0.405928\n",
      "(4, 6, 1)  0.447165\n",
      "(4, 6, 2)  0.447165\n",
      "(4, 6, 3)  0.447165\n",
      "(4, 6, 4)  0.367268\n",
      "(4, 6, 5)  0.376289\n",
      "(4, 6, 6)  0.367912\n",
      "(4, 6, 7)  0.365979\n",
      "(4, 6, 8)  0.447165\n",
      "(4, 6, 9)  0.375\n",
      "(4, 7)     0.366624\n",
      "(4, 7, 1)  0.410438\n",
      "(4, 7, 2)  0.393686\n",
      "(4, 7, 3)  0.409794\n",
      "(4, 7, 4)  0.447165\n",
      "(4, 7, 5)  0.378222\n",
      "(4, 7, 6)  0.405928\n",
      "(4, 7, 7)  0.394974\n",
      "(4, 7, 8)  0.37049\n",
      "(4, 7, 9)  0.358892\n",
      "(4, 8)     0.367268\n",
      "(4, 8, 1)  0.447165\n",
      "(4, 8, 2)  0.381443\n",
      "(4, 8, 3)  0.445232\n",
      "(4, 8, 4)  0.367268\n",
      "(4, 8, 5)  0.382732\n",
      "(4, 8, 6)  0.357603\n",
      "(4, 8, 7)  0.385309\n",
      "(4, 8, 8)  0.366624\n",
      "(4, 8, 9)  0.376933\n",
      "(4, 9)     0.429124\n",
      "(4, 9, 1)  0.436856\n",
      "(4, 9, 2)  0.381443\n",
      "(4, 9, 3)  0.419459\n",
      "(4, 9, 4)  0.369845\n",
      "(4, 9, 5)  0.369201\n",
      "(4, 9, 6)  0.409149\n",
      "(4, 9, 7)  0.380155\n",
      "(4, 9, 8)  0.389175\n",
      "(4, 9, 9)  0.366624\n",
      "(5,)       0.125\n",
      "(5, 1)     0.550902\n",
      "(5, 2)     0.447165\n",
      "(5, 3)     0.4375\n",
      "(5, 4)     0.447165\n",
      "(5, 5)     0.501289\n",
      "(5, 6)     0.262242\n",
      "(5, 7)     0.385309\n",
      "(5, 8)     0.375644\n",
      "(5, 9)     0.429124\n",
      "(5, 1)     0.550902\n",
      "(5, 1, 1)  0.550902\n",
      "(5, 1, 2)  0.447165\n",
      "(5, 1, 3)  0.447165\n",
      "(5, 1, 4)  0.478737\n",
      "(5, 1, 5)  0.447165\n",
      "(5, 1, 6)  0.447165\n",
      "(5, 1, 7)  0.447165\n",
      "(5, 1, 8)  0.445876\n",
      "(5, 1, 9)  0.451031\n",
      "(5, 2)     0.447165\n",
      "(5, 2, 1)  0.552835\n",
      "(5, 2, 2)  0.443943\n",
      "(5, 2, 3)  0.409794\n",
      "(5, 2, 4)  0.378866\n",
      "(5, 2, 5)  0.404639\n",
      "(5, 2, 6)  0.435567\n",
      "(5, 2, 7)  0.384665\n",
      "(5, 2, 8)  0.44201\n",
      "(5, 2, 9)  0.431701\n",
      "(5, 3)     0.4375\n",
      "(5, 3, 1)  0.447165\n",
      "(5, 3, 2)  0.448454\n",
      "(5, 3, 3)  0.375644\n",
      "(5, 3, 4)  0.377577\n",
      "(5, 3, 5)  0.367268\n",
      "(5, 3, 6)  0.542526\n",
      "(5, 3, 7)  0.462629\n",
      "(5, 3, 8)  0.374356\n",
      "(5, 3, 9)  0.382088\n",
      "(5, 4)     0.447165\n",
      "(5, 4, 1)  0.550258\n",
      "(5, 4, 2)  0.552835\n",
      "(5, 4, 3)  0.447165\n",
      "(5, 4, 4)  0.554768\n",
      "(5, 4, 5)  0.447809\n",
      "(5, 4, 6)  0.447165\n",
      "(5, 4, 7)  0.415593\n",
      "(5, 4, 8)  0.552835\n",
      "(5, 4, 9)  0.37951\n",
      "(5, 5)     0.501289\n",
      "(5, 5, 1)  0.552835\n",
      "(5, 5, 2)  0.552835\n",
      "(5, 5, 3)  0.358892\n",
      "(5, 5, 4)  0.445232\n",
      "(5, 5, 5)  0.376933\n",
      "(5, 5, 6)  0.452964\n",
      "(5, 5, 7)  0.373711\n",
      "(5, 5, 8)  0.387887\n",
      "(5, 5, 9)  0.402706\n",
      "(5, 6)     0.262242\n",
      "(5, 6, 1)  0.552191\n",
      "(5, 6, 2)  0.447165\n",
      "(5, 6, 3)  0.447165\n",
      "(5, 6, 4)  0.552835\n",
      "(5, 6, 5)  0.385954\n",
      "(5, 6, 6)  0.378866\n",
      "(5, 6, 7)  0.44201\n",
      "(5, 6, 8)  0.37951\n",
      "(5, 6, 9)  0.371778\n",
      "(5, 7)     0.385309\n",
      "(5, 7, 1)  0.369845\n",
      "(5, 7, 2)  0.447165\n",
      "(5, 7, 3)  0.400773\n",
      "(5, 7, 4)  0.447165\n",
      "(5, 7, 5)  0.364691\n",
      "(5, 7, 6)  0.391108\n",
      "(5, 7, 7)  0.387887\n",
      "(5, 7, 8)  0.39884\n",
      "(5, 7, 9)  0.43299\n",
      "(5, 8)     0.375644\n",
      "(5, 8, 1)  0.447165\n",
      "(5, 8, 2)  0.424613\n",
      "(5, 8, 3)  0.447165\n",
      "(5, 8, 4)  0.367912\n",
      "(5, 8, 5)  0.394974\n",
      "(5, 8, 6)  0.402062\n",
      "(5, 8, 7)  0.421392\n",
      "(5, 8, 8)  0.385954\n",
      "(5, 8, 9)  0.377577\n",
      "(5, 9)     0.429124\n",
      "(5, 9, 1)  0.429768\n",
      "(5, 9, 2)  0.447165\n",
      "(5, 9, 3)  0.37951\n",
      "(5, 9, 4)  0.391753\n",
      "(5, 9, 5)  0.545103\n",
      "(5, 9, 6)  0.398196\n",
      "(5, 9, 7)  0.487113\n",
      "(5, 9, 8)  0.414948\n",
      "(5, 9, 9)  0.507088\n",
      "(6,)       0.439433\n",
      "(6, 1)     0.552835\n",
      "(6, 2)     0.447165\n",
      "(6, 3)     0.402706\n",
      "(6, 4)     0.527062\n",
      "(6, 5)     0.414948\n",
      "(6, 6)     0.378222\n",
      "(6, 7)     0.38982\n",
      "(6, 8)     0.471005\n",
      "(6, 9)     0.375644\n",
      "(6, 1)     0.552835\n",
      "(6, 1, 1)  0.552835\n",
      "(6, 1, 2)  0.447165\n",
      "(6, 1, 3)  0.447165\n",
      "(6, 1, 4)  0.447165\n",
      "(6, 1, 5)  0.454253\n",
      "(6, 1, 6)  0.482603\n",
      "(6, 1, 7)  0.41817\n",
      "(6, 1, 8)  0.396263\n",
      "(6, 1, 9)  0.372423\n",
      "(6, 2)     0.447165\n",
      "(6, 2, 1)  0.447165\n",
      "(6, 2, 2)  0.378222\n",
      "(6, 2, 3)  0.357603\n",
      "(6, 2, 4)  0.375\n",
      "(6, 2, 5)  0.37951\n",
      "(6, 2, 6)  0.447165\n",
      "(6, 2, 7)  0.447165\n",
      "(6, 2, 8)  0.371134\n",
      "(6, 2, 9)  0.447165\n",
      "(6, 3)     0.402706\n",
      "(6, 3, 1)  0.432345\n",
      "(6, 3, 2)  0.397552\n",
      "(6, 3, 3)  0.378866\n",
      "(6, 3, 4)  0.396907\n",
      "(6, 3, 5)  0.367268\n",
      "(6, 3, 6)  0.380799\n",
      "(6, 3, 7)  0.378866\n",
      "(6, 3, 8)  0.365979\n",
      "(6, 3, 9)  0.376289\n",
      "(6, 4)     0.527062\n",
      "(6, 4, 1)  0.447165\n",
      "(6, 4, 2)  0.376933\n",
      "(6, 4, 3)  0.376933\n",
      "(6, 4, 4)  0.447165\n",
      "(6, 4, 5)  0.367912\n",
      "(6, 4, 6)  0.511598\n",
      "(6, 4, 7)  0.37049\n",
      "(6, 4, 8)  0.548969\n",
      "(6, 4, 9)  0.369201\n",
      "(6, 5)     0.414948\n",
      "(6, 5, 1)  0.405928\n",
      "(6, 5, 2)  0.447165\n",
      "(6, 5, 3)  0.552835\n",
      "(6, 5, 4)  0.39884\n",
      "(6, 5, 5)  0.378866\n",
      "(6, 5, 6)  0.375644\n",
      "(6, 5, 7)  0.415593\n",
      "(6, 5, 8)  0.554124\n",
      "(6, 5, 9)  0.365335\n",
      "(6, 6)     0.378222\n",
      "(6, 6, 1)  0.364691\n",
      "(6, 6, 2)  0.397552\n",
      "(6, 6, 3)  0.447165\n",
      "(6, 6, 4)  0.438144\n",
      "(6, 6, 5)  0.362758\n",
      "(6, 6, 6)  0.543814\n",
      "(6, 6, 7)  0.388531\n",
      "(6, 6, 8)  0.420747\n",
      "(6, 6, 9)  0.378866\n",
      "(6, 7)     0.38982\n",
      "(6, 7, 1)  0.361469\n",
      "(6, 7, 2)  0.447165\n",
      "(6, 7, 3)  0.472294\n",
      "(6, 7, 4)  0.354381\n",
      "(6, 7, 5)  0.393041\n",
      "(6, 7, 6)  0.387242\n",
      "(6, 7, 7)  0.501289\n",
      "(6, 7, 8)  0.360825\n",
      "(6, 7, 9)  0.358247\n",
      "(6, 8)     0.471005\n",
      "(6, 8, 1)  0.447165\n",
      "(6, 8, 2)  0.447165\n",
      "(6, 8, 3)  0.447165\n",
      "(6, 8, 4)  0.373711\n",
      "(6, 8, 5)  0.382088\n",
      "(6, 8, 6)  0.385309\n",
      "(6, 8, 7)  0.365979\n",
      "(6, 8, 8)  0.440722\n",
      "(6, 8, 9)  0.369845\n",
      "(6, 9)     0.375644\n",
      "(6, 9, 1)  0.384021\n",
      "(6, 9, 2)  0.447165\n",
      "(6, 9, 3)  0.372423\n",
      "(6, 9, 4)  0.411727\n",
      "(6, 9, 5)  0.405928\n",
      "(6, 9, 6)  0.552835\n",
      "(6, 9, 7)  0.364046\n",
      "(6, 9, 8)  0.385309\n",
      "(6, 9, 9)  0.378222\n",
      "(7,)       0.256443\n",
      "(7, 1)     0.447165\n",
      "(7, 2)     0.447165\n",
      "(7, 3)     0.382088\n",
      "(7, 4)     0.422036\n",
      "(7, 5)     0.37951\n",
      "(7, 6)     0.32732\n",
      "(7, 7)     0.429768\n",
      "(7, 8)     0.466495\n",
      "(7, 9)     0.449098\n",
      "(7, 1)     0.447165\n",
      "(7, 1, 1)  0.552835\n",
      "(7, 1, 2)  0.447165\n",
      "(7, 1, 3)  0.447165\n",
      "(7, 1, 4)  0.447165\n",
      "(7, 1, 5)  0.447165\n",
      "(7, 1, 6)  0.447165\n",
      "(7, 1, 7)  0.447165\n",
      "(7, 1, 8)  0.447165\n",
      "(7, 1, 9)  0.447165\n",
      "(7, 2)     0.447165\n",
      "(7, 2, 1)  0.552835\n",
      "(7, 2, 2)  0.551546\n",
      "(7, 2, 3)  0.447165\n",
      "(7, 2, 4)  0.447165\n",
      "(7, 2, 5)  0.447165\n",
      "(7, 2, 6)  0.447165\n",
      "(7, 2, 7)  0.414948\n",
      "(7, 2, 8)  0.418814\n",
      "(7, 2, 9)  0.447165\n",
      "(7, 3)     0.382088\n",
      "(7, 3, 1)  0.552835\n",
      "(7, 3, 2)  0.447165\n",
      "(7, 3, 3)  0.466495\n",
      "(7, 3, 4)  0.391753\n",
      "(7, 3, 5)  0.438789\n",
      "(7, 3, 6)  0.416237\n",
      "(7, 3, 7)  0.447165\n",
      "(7, 3, 8)  0.372423\n",
      "(7, 3, 9)  0.429768\n",
      "(7, 4)     0.422036\n",
      "(7, 4, 1)  0.367268\n",
      "(7, 4, 2)  0.432345\n",
      "(7, 4, 3)  0.431057\n",
      "(7, 4, 4)  0.439433\n",
      "(7, 4, 5)  0.447165\n",
      "(7, 4, 6)  0.398196\n",
      "(7, 4, 7)  0.447165\n",
      "(7, 4, 8)  0.373067\n",
      "(7, 4, 9)  0.385954\n",
      "(7, 5)     0.37951\n",
      "(7, 5, 1)  0.551546\n",
      "(7, 5, 2)  0.447165\n",
      "(7, 5, 3)  0.527062\n",
      "(7, 5, 4)  0.447165\n",
      "(7, 5, 5)  0.382732\n",
      "(7, 5, 6)  0.447165\n",
      "(7, 5, 7)  0.552835\n",
      "(7, 5, 8)  0.339562\n",
      "(7, 5, 9)  0.416237\n",
      "(7, 6)     0.32732\n",
      "(7, 6, 1)  0.447165\n",
      "(7, 6, 2)  0.447165\n",
      "(7, 6, 3)  0.395619\n",
      "(7, 6, 4)  0.444588\n",
      "(7, 6, 5)  0.373711\n",
      "(7, 6, 6)  0.543814\n",
      "(7, 6, 7)  0.422036\n",
      "(7, 6, 8)  0.360825\n",
      "(7, 6, 9)  0.472938\n",
      "(7, 7)     0.429768\n",
      "(7, 7, 1)  0.447165\n",
      "(7, 7, 2)  0.447165\n",
      "(7, 7, 3)  0.447165\n",
      "(7, 7, 4)  0.552835\n",
      "(7, 7, 5)  0.214562\n",
      "(7, 7, 6)  0.555412\n",
      "(7, 7, 7)  0.552835\n",
      "(7, 7, 8)  0.550258\n",
      "(7, 7, 9)  0.367912\n",
      "(7, 8)     0.466495\n",
      "(7, 8, 1)  0.447165\n",
      "(7, 8, 2)  0.419459\n",
      "(7, 8, 3)  0.434923\n",
      "(7, 8, 4)  0.447165\n",
      "(7, 8, 5)  0.344072\n",
      "(7, 8, 6)  0.381443\n",
      "(7, 8, 7)  0.37049\n",
      "(7, 8, 8)  0.48518\n",
      "(7, 8, 9)  0.399485\n",
      "(7, 9)     0.449098\n",
      "(7, 9, 1)  0.552835\n",
      "(7, 9, 2)  0.447165\n",
      "(7, 9, 3)  0.447165\n",
      "(7, 9, 4)  0.552835\n",
      "(7, 9, 5)  0.494845\n",
      "(7, 9, 6)  0.378222\n",
      "(7, 9, 7)  0.463273\n",
      "(7, 9, 8)  0.456186\n",
      "(7, 9, 9)  0.403995\n",
      "(8,)       0.559278\n",
      "(8, 1)     0.447165\n",
      "(8, 2)     0.447165\n",
      "(8, 3)     0.510954\n",
      "(8, 4)     0.399485\n",
      "(8, 5)     0.378222\n",
      "(8, 6)     0.43299\n",
      "(8, 7)     0.414948\n",
      "(8, 8)     0.499356\n",
      "(8, 9)     0.376289\n",
      "(8, 1)     0.447165\n",
      "(8, 1, 1)  0.377577\n",
      "(8, 1, 2)  0.447165\n",
      "(8, 1, 3)  0.432345\n",
      "(8, 1, 4)  0.443943\n",
      "(8, 1, 5)  0.447165\n",
      "(8, 1, 6)  0.420747\n",
      "(8, 1, 7)  0.416881\n",
      "(8, 1, 8)  0.436211\n",
      "(8, 1, 9)  0.384665\n",
      "(8, 2)     0.447165\n",
      "(8, 2, 1)  0.447165\n",
      "(8, 2, 2)  0.447165\n",
      "(8, 2, 3)  0.367912\n",
      "(8, 2, 4)  0.384665\n",
      "(8, 2, 5)  0.420747\n",
      "(8, 2, 6)  0.463918\n",
      "(8, 2, 7)  0.444588\n",
      "(8, 2, 8)  0.449742\n",
      "(8, 2, 9)  0.364046\n",
      "(8, 3)     0.510954\n",
      "(8, 3, 1)  0.364046\n",
      "(8, 3, 2)  0.378222\n",
      "(8, 3, 3)  0.447165\n",
      "(8, 3, 4)  0.366624\n",
      "(8, 3, 5)  0.447165\n",
      "(8, 3, 6)  0.381443\n",
      "(8, 3, 7)  0.364046\n",
      "(8, 3, 8)  0.380155\n",
      "(8, 3, 9)  0.383376\n",
      "(8, 4)     0.399485\n",
      "(8, 4, 1)  0.447165\n",
      "(8, 4, 2)  0.448454\n",
      "(8, 4, 3)  0.446521\n",
      "(8, 4, 4)  0.386598\n",
      "(8, 4, 5)  0.362113\n",
      "(8, 4, 6)  0.395619\n",
      "(8, 4, 7)  0.408505\n",
      "(8, 4, 8)  0.401418\n",
      "(8, 4, 9)  0.416237\n",
      "(8, 5)     0.378222\n",
      "(8, 5, 1)  0.447165\n",
      "(8, 5, 2)  0.368557\n",
      "(8, 5, 3)  0.37951\n",
      "(8, 5, 4)  0.386598\n",
      "(8, 5, 5)  0.376289\n",
      "(8, 5, 6)  0.372423\n",
      "(8, 5, 7)  0.387887\n",
      "(8, 5, 8)  0.373067\n",
      "(8, 5, 9)  0.414304\n",
      "(8, 6)     0.43299\n",
      "(8, 6, 1)  0.453608\n",
      "(8, 6, 2)  0.396907\n",
      "(8, 6, 3)  0.405928\n",
      "(8, 6, 4)  0.395619\n",
      "(8, 6, 5)  0.418814\n",
      "(8, 6, 6)  0.385954\n",
      "(8, 6, 7)  0.388531\n",
      "(8, 6, 8)  0.585696\n",
      "(8, 6, 9)  0.375\n",
      "(8, 7)     0.414948\n",
      "(8, 7, 1)  0.386598\n",
      "(8, 7, 2)  0.376289\n",
      "(8, 7, 3)  0.446521\n",
      "(8, 7, 4)  0.415593\n",
      "(8, 7, 5)  0.552835\n",
      "(8, 7, 6)  0.516108\n",
      "(8, 7, 7)  0.382088\n",
      "(8, 7, 8)  0.451031\n",
      "(8, 7, 9)  0.382732\n",
      "(8, 8)     0.499356\n",
      "(8, 8, 1)  0.447165\n",
      "(8, 8, 2)  0.447165\n",
      "(8, 8, 3)  0.371134\n",
      "(8, 8, 4)  0.447165\n",
      "(8, 8, 5)  0.367912\n",
      "(8, 8, 6)  0.373711\n",
      "(8, 8, 7)  0.368557\n",
      "(8, 8, 8)  0.401418\n",
      "(8, 8, 9)  0.454253\n",
      "(8, 9)     0.376289\n",
      "(8, 9, 1)  0.447165\n",
      "(8, 9, 2)  0.447165\n",
      "(8, 9, 3)  0.451675\n",
      "(8, 9, 4)  0.447165\n",
      "(8, 9, 5)  0.394974\n",
      "(8, 9, 6)  0.387887\n",
      "(8, 9, 7)  0.412371\n",
      "(8, 9, 8)  0.419459\n",
      "(8, 9, 9)  0.447165\n",
      "(9,)       0.39884\n",
      "(9, 1)     0.447165\n",
      "(9, 2)     0.522552\n",
      "(9, 3)     0.404639\n",
      "(9, 4)     0.503866\n",
      "(9, 5)     0.579897\n",
      "(9, 6)     0.400773\n",
      "(9, 7)     0.513531\n",
      "(9, 8)     0.516753\n",
      "(9, 9)     0.380799\n",
      "(9, 1)     0.447165\n",
      "(9, 1, 1)  0.447165\n",
      "(9, 1, 2)  0.447165\n",
      "(9, 1, 3)  0.45232\n",
      "(9, 1, 4)  0.451675\n",
      "(9, 1, 5)  0.447165\n",
      "(9, 1, 6)  0.378222\n",
      "(9, 1, 7)  0.497423\n",
      "(9, 1, 8)  0.409794\n",
      "(9, 1, 9)  0.448454\n",
      "(9, 2)     0.522552\n",
      "(9, 2, 1)  0.552835\n",
      "(9, 2, 2)  0.375644\n",
      "(9, 2, 3)  0.37951\n",
      "(9, 2, 4)  0.380799\n",
      "(9, 2, 5)  0.446521\n",
      "(9, 2, 6)  0.399485\n",
      "(9, 2, 7)  0.375644\n",
      "(9, 2, 8)  0.373711\n",
      "(9, 2, 9)  0.403351\n",
      "(9, 3)     0.404639\n",
      "(9, 3, 1)  0.445876\n",
      "(9, 3, 2)  0.338273\n",
      "(9, 3, 3)  0.460696\n",
      "(9, 3, 4)  0.447165\n",
      "(9, 3, 5)  0.556057\n",
      "(9, 3, 6)  0.409794\n",
      "(9, 3, 7)  0.422036\n",
      "(9, 3, 8)  0.443299\n",
      "(9, 3, 9)  0.444588\n",
      "(9, 4)     0.503866\n",
      "(9, 4, 1)  0.552835\n",
      "(9, 4, 2)  0.552835\n",
      "(9, 4, 3)  0.447165\n",
      "(9, 4, 4)  0.364691\n",
      "(9, 4, 5)  0.485825\n",
      "(9, 4, 6)  0.550902\n",
      "(9, 4, 7)  0.447165\n",
      "(9, 4, 8)  0.436211\n",
      "(9, 4, 9)  0.329253\n",
      "(9, 5)     0.579897\n",
      "(9, 5, 1)  0.447165\n",
      "(9, 5, 2)  0.401418\n",
      "(9, 5, 3)  0.465206\n",
      "(9, 5, 4)  0.490979\n",
      "(9, 5, 5)  0.413015\n",
      "(9, 5, 6)  0.380155\n",
      "(9, 5, 7)  0.390464\n",
      "(9, 5, 8)  0.494201\n",
      "(9, 5, 9)  0.41817\n",
      "(9, 6)     0.400773\n",
      "(9, 6, 1)  0.447165\n",
      "(9, 6, 2)  0.447165\n",
      "(9, 6, 3)  0.552835\n",
      "(9, 6, 4)  0.491624\n",
      "(9, 6, 5)  0.373067\n",
      "(9, 6, 6)  0.367268\n",
      "(9, 6, 7)  0.448454\n",
      "(9, 6, 8)  0.375644\n",
      "(9, 6, 9)  0.367912\n",
      "(9, 7)     0.513531\n",
      "(9, 7, 1)  0.447165\n",
      "(9, 7, 2)  0.552835\n",
      "(9, 7, 3)  0.552835\n",
      "(9, 7, 4)  0.552835\n",
      "(9, 7, 5)  0.423969\n",
      "(9, 7, 6)  0.396907\n",
      "(9, 7, 7)  0.466495\n",
      "(9, 7, 8)  0.425258\n",
      "(9, 7, 9)  0.428479\n",
      "(9, 8)     0.516753\n",
      "(9, 8, 1)  0.552835\n",
      "(9, 8, 2)  0.448454\n",
      "(9, 8, 3)  0.427835\n",
      "(9, 8, 4)  0.445876\n",
      "(9, 8, 5)  0.552835\n",
      "(9, 8, 6)  0.554768\n",
      "(9, 8, 7)  0.387242\n",
      "(9, 8, 8)  0.388531\n",
      "(9, 8, 9)  0.461985\n",
      "(9, 9)     0.380799\n",
      "(9, 9, 1)  0.447165\n",
      "(9, 9, 2)  0.447165\n",
      "(9, 9, 3)  0.569588\n",
      "(9, 9, 4)  0.366624\n",
      "(9, 9, 5)  0.448454\n",
      "(9, 9, 6)  0.371778\n",
      "(9, 9, 7)  0.365335\n",
      "(9, 9, 8)  0.391108\n",
      "(9, 9, 9)  0.380155\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table, headers=['Size', 'Error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.index(min(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size[error.index(min(error))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
